{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data.drop(['Name','Ticket','PassengerId'],1,inplace=True)\n",
    "    data.loc[data['Age'].isnull(),'Age'] = -10\n",
    "    data.loc[data['Cabin'].isnull(),'Cabin']=\"NaaN\"\n",
    "    data.loc[data['Embarked'].isnull(),'Embarked']=\"N\"\n",
    "#     print(set(data['Embarked']))\n",
    "#     label_encoder = LabelEncoder()\n",
    "#     data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
    "#     data['Cabin'] = label_encoder.fit_transform(data['Cabin'])\n",
    "#     data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_dummy_columns( d, columns ):\n",
    "    missing_cols = set( columns ) - set( d.columns )\n",
    "    for c in missing_cols:\n",
    "        d[c] = 0\n",
    "\n",
    "def fix_columns( d, columns ):  \n",
    "\n",
    "    add_missing_dummy_columns( d, columns )\n",
    "\n",
    "    # make sure we have all the columns we need\n",
    "    assert( set( columns ) - set( d.columns ) == set())\n",
    "\n",
    "    extra_cols = set( d.columns ) - set( columns )\n",
    "#     if extra_cols:\n",
    "#         print (\"extra columns:\", extra_cols)\n",
    "\n",
    "    d = d[ columns ]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_self(data):\n",
    "    for column in data:\n",
    "      if(not(isinstance(data[column][0], (int, float,np.int64,np.float64)))):\n",
    "        enc = preprocessing.LabelEncoder()\n",
    "        enc.fit(data[column])\n",
    "        new_data=enc.transform(data[column])\n",
    "        new_data=new_data.reshape(-1,1)\n",
    "        ohe = preprocessing.OneHotEncoder(sparse=False) #Easier to read\n",
    "        new_data=ohe.fit_transform(new_data)\n",
    "        print(new_data)\n",
    "        data=data.drop(column,axis=1)\n",
    "        data=data.join(pd.DataFrame(new_data))\n",
    "#         print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.5 [0]\n",
      "47.0 [0]\n",
      "62.0 [1]\n",
      "27.0 [1]\n",
      "22.0 [0]\n",
      "14.0 [0]\n",
      "30.0 [0]\n",
      "26.0 [0]\n",
      "18.0 [1]\n",
      "21.0 [0]\n",
      "-10.0 [0]\n",
      "46.0 [0]\n",
      "23.0 [1]\n",
      "63.0 [1]\n",
      "47.0 [1]\n",
      "24.0 [1]\n",
      "35.0 [0]\n",
      "21.0 [1]\n",
      "27.0 [0]\n",
      "45.0 [0]\n",
      "55.0 [0]\n",
      "9.0 [1]\n",
      "-10.0 [1]\n",
      "21.0 [1]\n",
      "48.0 [1]\n",
      "50.0 [0]\n",
      "22.0 [1]\n",
      "22.5 [1]\n",
      "41.0 [1]\n",
      "-10.0 [0]\n",
      "50.0 [0]\n",
      "24.0 [0]\n",
      "33.0 [1]\n",
      "-10.0 [0]\n",
      "30.0 [1]\n",
      "18.5 [1]\n",
      "-10.0 [0]\n",
      "21.0 [0]\n",
      "25.0 [0]\n",
      "-10.0 [1]\n",
      "39.0 [0]\n",
      "-10.0 [1]\n",
      "41.0 [0]\n",
      "30.0 [1]\n",
      "45.0 [1]\n",
      "25.0 [0]\n",
      "45.0 [0]\n",
      "-10.0 [0]\n",
      "60.0 [1]\n",
      "36.0 [1]\n",
      "24.0 [1]\n",
      "27.0 [1]\n",
      "20.0 [1]\n",
      "28.0 [1]\n",
      "-10.0 [0]\n",
      "10.0 [0]\n",
      "35.0 [0]\n",
      "25.0 [0]\n",
      "-10.0 [0]\n",
      "36.0 [1]\n",
      "17.0 [0]\n",
      "32.0 [0]\n",
      "18.0 [0]\n",
      "22.0 [1]\n",
      "13.0 [0]\n",
      "-10.0 [1]\n",
      "18.0 [0]\n",
      "47.0 [0]\n",
      "31.0 [1]\n",
      "60.0 [1]\n",
      "24.0 [1]\n",
      "21.0 [0]\n",
      "29.0 [0]\n",
      "28.5 [1]\n",
      "35.0 [1]\n",
      "32.5 [0]\n",
      "-10.0 [0]\n",
      "55.0 [1]\n",
      "30.0 [0]\n",
      "24.0 [1]\n",
      "6.0 [1]\n",
      "67.0 [0]\n",
      "49.0 [0]\n",
      "-10.0 [0]\n",
      "-10.0 [1]\n",
      "-10.0 [0]\n",
      "27.0 [1]\n",
      "18.0 [1]\n",
      "-10.0 [1]\n",
      "2.0 [1]\n",
      "22.0 [0]\n",
      "-10.0 [0]\n",
      "27.0 [1]\n",
      "-10.0 [0]\n",
      "25.0 [1]\n",
      "25.0 [0]\n",
      "76.0 [1]\n",
      "29.0 [0]\n",
      "20.0 [1]\n",
      "33.0 [0]\n",
      "43.0 [1]\n",
      "27.0 [0]\n",
      "-10.0 [0]\n",
      "26.0 [0]\n",
      "16.0 [1]\n",
      "28.0 [0]\n",
      "21.0 [0]\n",
      "-10.0 [0]\n",
      "-10.0 [0]\n",
      "18.5 [1]\n",
      "41.0 [0]\n",
      "-10.0 [1]\n",
      "36.0 [1]\n",
      "18.5 [0]\n",
      "63.0 [1]\n",
      "18.0 [1]\n",
      "-10.0 [0]\n",
      "1.0 [1]\n",
      "36.0 [1]\n",
      "29.0 [1]\n",
      "12.0 [1]\n",
      "-10.0 [0]\n",
      "35.0 [1]\n",
      "28.0 [0]\n",
      "-10.0 [0]\n",
      "17.0 [0]\n",
      "22.0 [0]\n",
      "-10.0 [1]\n",
      "42.0 [0]\n",
      "24.0 [0]\n",
      "32.0 [0]\n",
      "53.0 [0]\n",
      "-10.0 [0]\n",
      "-10.0 [0]\n",
      "43.0 [0]\n",
      "24.0 [0]\n",
      "26.5 [0]\n",
      "26.0 [0]\n",
      "23.0 [0]\n",
      "40.0 [0]\n",
      "10.0 [0]\n",
      "33.0 [1]\n",
      "61.0 [0]\n",
      "28.0 [0]\n",
      "42.0 [1]\n",
      "31.0 [1]\n",
      "-10.0 [0]\n",
      "22.0 [0]\n",
      "-10.0 [1]\n",
      "30.0 [0]\n",
      "23.0 [1]\n",
      "-10.0 [0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b59b9f3c6ac5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_data1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \"\"\"\n\u001b[0;32m    411\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tree_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    375\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('C:/Users/Som/AI Workshop/Titanic Forecast/data/train.csv')\n",
    "test_data1=pd.read_csv('C:/Users/Som/AI Workshop/Titanic Forecast/data/test.csv')\n",
    "output=data['Survived']\n",
    "data.drop(['Survived'],1,inplace=True)\n",
    "test_data=preprocess_data(data)\n",
    "test_data1=preprocess_data(test_data1)\n",
    "test_data=pd.get_dummies(test_data)\n",
    "test_data1=pd.get_dummies(test_data1)\n",
    "test_data1=fix_columns(test_data1,test_data.columns)\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(test_data,output)\n",
    "for index,row in test_data1.iterrows():\n",
    "   print(row['Age'],clf.predict([row]))\n",
    "\n",
    "\n",
    "# print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:/Users/Som/AI Workshop/Titanic Forecast/data/train.csv')\n",
    "test_data=pd.read_csv('C:/Users/Som/AI Workshop/Titanic Forecast/data/test.csv')\n",
    "output=data['Survived']\n",
    "data.drop(['Survived'],1,inplace=True)\n",
    "# data=preprocess_data(data)\n",
    "data.drop(['Name','Ticket','PassengerId'],1,inplace=True)\n",
    "data.loc[data['Age'].isnull(),'Age'] = -10\n",
    "data.loc[data['Cabin'].isnull(),'Cabin']=\"NaaN\"\n",
    "data.loc[data['Embarked'].isnull(),'Embarked']=\"N\"\n",
    "test_data=preprocess_data(test_data)\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(data,output)\n",
    "print(clf.score(data,output))\n",
    "clf.predict([test_data.loc[0]])\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"titanic\") \n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=data.columns,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define example\n",
    "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "values = array(data)\n",
    "print(values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "# print(onehot_encoded)\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. INSTANTIATE\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# 2. FIT\n",
    "enc.fit(data)\n",
    "\n",
    "# 3. Transform\n",
    "onehotlabels = enc.transform(data).toarray()\n",
    "onehotlabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(onehotlabels)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

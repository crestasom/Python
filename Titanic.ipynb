{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Som\\\\Anaconda3\\\\envs\\\\ai\\\\python.exe'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import statistics as sts\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data.drop(['Name','Ticket','PassengerId'],1,inplace=True)\n",
    "    data['Age']=data['Age'].fillna(sts.median(data['Age']))\n",
    "#     med=sts.median(data['age'])\n",
    "#     data.fillna\n",
    "#     data.loc[data['Age'].isnull(),'Age'] = -10\n",
    "#     data.loc[data['Cabin'].isnull(),'Cabin']=\"NaaN\"\n",
    "#     data.loc[data['Embarked'].isnull(),'Embarked']=\"N\"\n",
    "#     print(set(data['Embarked']))\n",
    "#     label_encoder = LabelEncoder()\n",
    "#     data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
    "#     data['Cabin'] = label_encoder.fit_transform(data['Cabin'])\n",
    "#     data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_dummy_columns( d, columns ):\n",
    "    missing_cols = set( columns ) - set( d.columns )\n",
    "    for c in missing_cols:\n",
    "        d[c] = 0\n",
    "\n",
    "def fix_columns( d, columns ):  \n",
    "\n",
    "    add_missing_dummy_columns( d, columns )\n",
    "\n",
    "    # make sure we have all the columns we need\n",
    "    assert( set( columns ) - set( d.columns ) == set())\n",
    "    \n",
    "    extra_cols = set( d.columns ) - set( columns )\n",
    "#     if extra_cols:\n",
    "#         print (\"extra columns:\", extra_cols)\n",
    "\n",
    "    d = d[ columns ]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex  Age  SibSp  Parch  Fare Cabin Embarked\n",
      "0       NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "1       NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "2       NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "3       NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "4       NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "5       NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "6       NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "7       NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "8       NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "9       NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "10      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "11      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "12      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "13      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "14      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "15      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "16      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "17      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "18      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "19      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "20      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "21      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "22      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "23      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "24      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "25      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "26      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "27      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "28      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "29      NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "..      ...  ...  ...    ...    ...   ...   ...      ...\n",
      "861     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "862     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "863     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "864     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "865     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "866     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "867     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "868     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "869     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "870     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "871     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "872     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "873     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "874     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "875     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "876     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "877     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "878     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "879     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "880     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "881     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "882     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "883     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "884     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "885     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "886     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "887     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "888     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "889     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "890     NaN  NaN  NaN    NaN    NaN   NaN   NaN      NaN\n",
      "\n",
      "[891 rows x 8 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-8c17294821f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfix_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# clf.predict(test_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \"\"\"\n\u001b[0;32m    764\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv('C:/Users/Som/AI Workshop/Titanic Forecast/data/train.csv')\n",
    "test_data=pd.read_csv('C:/Users/Som/AI Workshop/Titanic Forecast/data/test.csv')\n",
    "output=train_data['Survived']\n",
    "train_data.drop(['Survived'],1,inplace=True)\n",
    "train_data=preprocess_data(train_data)\n",
    "print(train_data[train_data.isnull()])\n",
    "test_data=preprocess_data(test_data)\n",
    "train_data=pd.get_dummies(train_data)\n",
    "test_data=pd.get_dummies(test_data)\n",
    "test_data=fix_columns(test_data,train_data.columns)\n",
    "clf=KNeighborsClassifier()\n",
    "clf.fit(train_data,output)\n",
    "clf.score(train_data,output)\n",
    "# clf.predict(test_data)\n",
    "\n",
    "# i=1\n",
    "\n",
    "# for index,row in test_data1.iterrows():\n",
    "#     print(i,row['Age'],clf.predict([row]))\n",
    "#     i=i+1\n",
    "\n",
    "\n",
    "# # print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(test_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data1.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:/Users/Som/AI Workshop/Titanic Forecast/data/train.csv')\n",
    "test_data=pd.read_csv('C:/Users/Som/AI Workshop/Titanic Forecast/data/test.csv')\n",
    "output=data['Survived']\n",
    "data.drop(['Survived'],1,inplace=True)\n",
    "# data=preprocess_data(data)\n",
    "data.drop(['Name','Ticket','PassengerId'],1,inplace=True)\n",
    "data.loc[data['Age'].isnull(),'Age'] = -10\n",
    "data.loc[data['Cabin'].isnull(),'Cabin']=\"NaaN\"\n",
    "data.loc[data['Embarked'].isnull(),'Embarked']=\"N\"\n",
    "test_data=preprocess_data(test_data)\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(data,output)\n",
    "print(clf.score(data,output))\n",
    "clf.predict([test_data.loc[0]])\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"titanic\") \n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=data.columns,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define example\n",
    "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "values = array(data)\n",
    "print(values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "# print(onehot_encoded)\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. INSTANTIATE\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# 2. FIT\n",
    "enc.fit(data)\n",
    "\n",
    "# 3. Transform\n",
    "onehotlabels = enc.transform(data).toarray()\n",
    "onehotlabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(onehotlabels)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.median(train_data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
